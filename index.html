<html>
<head>
  <meta name="viewport" content="width=device-width,initial-scale-1.0">
  <meta http-equiv="X-UA-Compatible" content="ie-edge">
<title>instagram-face machine learning</title>
  <style>
    body {
      margin: 0;
      padding: 10px;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      flex-direction: column;
    }
    canvas { position: absolute;}
  </style>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="face-api.js"></script>
  
  <script>
      Promise.all([
        faceapi.nets.faceRecognitionNet.loadFromUri('/'),
        faceapi.nets.tinyFaceDetector.loadFromUri('/'),
        faceapi.nets.ssdMobilenetv1.loadFromUri('/')                                            
        ]).then(start)
    
      function start() {console.log("started");}
  </script>
  
<script>
  function Getir(x) {
  
  $.ajax({
    url: "https://jsonp.afeld.me/?url=http%3A%2F%2Fmotyar.info%2Fwebscrapemaster%2Fapi%2F%3Furl%3Dhttps%3A%2F%2Fwww.instagram.com%2F"+x+"%26xpath%3D%2F%2Fhtml%2Fmeta%5B%40property%3Dog%3Aimage%5D",
    dataType: "json",
    success: function( response ) {
        document.getElementById("inst").innerHTML = '<img id="refImg" src="' + response[0].content + '">';
        updateResults();
        run();
    }
});
  }

</script>
  
  
  <script>
    const TINY_FACE_DETECTOR = 'tiny_face_detector'
let selectedFaceDetector = TINY_FACE_DETECTOR

// tiny_face_detector options
let inputSize = 128
let scoreThreshold = 0.5

function getFaceDetectorOptions() {
      new faceapi.TinyFaceDetectorOptions({ inputSize, scoreThreshold })
}

function getCurrentFaceDetectionNet() {
  console.log("gcfdn");
  console.log(faceapi.nets.tinyFaceDetector);
    return faceapi.nets.tinyFaceDetector
 }

function isFaceDetectionModelLoaded() {
  return !!getCurrentFaceDetectionNet().params
}

async function changeFaceDetector(detector) {
  console.log("cfd");

  if (!isFaceDetectionModelLoaded()) {
     console.log("nifdml");
    await getCurrentFaceDetectionNet().load('/')
  }
}

async function onSelectedFaceDetectorChanged(e) {
  selectedFaceDetector = e.target.value

  await changeFaceDetector(e.target.value)
  updateResults()
}

function initFaceDetectionControls() {
  const faceDetectorSelect = $('#selectFaceDetector')
  faceDetectorSelect.val(selectedFaceDetector)
  faceDetectorSelect.on('change', onSelectedFaceDetectorChanged)
  faceDetectorSelect.material_select()

  const inputSizeSelect = $('#inputSize')
  inputSizeSelect.val(inputSize)
  inputSizeSelect.on('change', onInputSizeChanged)
  inputSizeSelect.material_select()
}
    
  </script>
  
</head>
<body>
  <h1>profile name: <input type="text" name="ip" id="ip">
    <br>
    <button onclick="Getir(document.getElementById('ip').value)">Getir</button>
     
  </h1>
  <h2 id="inst"></h2>
  <img id="gandhi" src="gandhi.jpg">
      

  <script>

    async function uploadRefImage(e) {
      console.log("uploadRefImage()");
      const imgFile = $('#srcImg').get(0).files[0]
      const img = await faceapi.bufferToImage(imgFile)
      $('#refImg').get(0).src = img.src
      updateReferenceImageResults()
    }
    
    async function uploadQueryImage(e) {
      console.log("uploadQueryImage()");
      const imgFile = $('#queryImgUploadInput').get(0).files[0]
      const img = await faceapi.bufferToImage(imgFile)
      $('#queryImg').get(0).src = img.src
      updateQueryImageResults()
    }
    
    async function loadQueryImageFromUrl(url) {
      console.log("loadQueryImageFromUrl()");
      const img = await requestExternalImage($('#queryImgUrlInput').val())
      $('#queryImg').get(0).src = img.src
      updateQueryImageResults()
    }
    
    /*
    async function updateReferenceImageResults() {
      console.log("updateReferenceImageResults()");
      const inputImgEl = $('#refImg').get(0)
      const canvas = $('#refImgOverlay').get(0)
      const fullFaceDescriptions = await faceapi
        .detectAllFaces(inputImgEl, getFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors()
    }
    */
    
    // yeni yazıldı
    async function updateReferenceImageResults() {
      console.log("updateReferenceImageResults()");
      const inputImgEl = $('#gandhi').get(0).src;
      console.log(inputImgEl);
      //const canvas = $('#refImgOverlay').get(0)
      //var inp = document.getElementById("gandhi").src;
      const detections = await faceapi.detectAllFaces(inputImgEl);
      console.log(detections);
    }
    
    async function updateQueryImageResults() {
      console.log("updateQueryImageResults()");
      const inputImgEl = $('#queryImg').get(0)
      const canvas = $('#queryImgOverlay').get(0)
      const results = await faceapi
        .detectAllFaces(inputImgEl, getFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors()
      faceapi.matchDimensions(canvas, inputImgEl)
      // resize detection and landmarks in case displayed image is smaller than
      // original size
      const resizedResults = faceapi.resizeResults(results, inputImgEl)
      resizedResults.forEach(({ detection, descriptor }) => {
        const label = faceMatcher.findBestMatch(descriptor).toString()
        const options = { label }
        const drawBox = new faceapi.draw.DrawBox(detection.box, options)
        drawBox.draw(canvas)
      })
    }
    async function updateResults() {
      console.log("updateResults()");
      await updateReferenceImageResults()
      await updateQueryImageResults()
    }
    async function run() {
      // load face detection, face landmark model and face recognition models
      await changeFaceDetector('tiny_face_detector')
      //await faceapi.loadFaceLandmarkModel('/')
      await faceapi.loadFaceRecognitionModel('/')
    }
    /*
    $(document).ready(function() {
      renderNavBar('#navbar', 'face_recognition')
      initFaceDetectionControls()
      run()
    })
    */
  </script>
</body>
</html>
