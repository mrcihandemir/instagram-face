<html>
<head>
  <meta name="viewport" content="width=device-width,initial-scale-1.0">
  <meta http-equiv="X-UA-Compatible" content="ie-edge">
<title>instagram-face machine learning</title>
  <style>
    body {
      margin: 0;
      padding: 10px;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      flex-direction: column;
    }
    canvas { position: absolute;}
  </style>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="face-api.js"></script>
  <script src="common.js"></script>
  <script src="index.js"></script>
  
  <script>
      Promise.all([
        faceapi.nets.faceRecognitionNet.loadFromUri('/'),
        faceapi.nets.tinyFaceDetector.loadFromUri('/'),
        faceapi.nets.ssdMobilenetv1.loadFromUri('/')                                            
        ]).then(start)
    
      function start() {console.log("started");}
  </script>
  
<script>
  function Getir(x) {
  
  $.ajax({
    url: "https://jsonp.afeld.me/?url=http%3A%2F%2Fmotyar.info%2Fwebscrapemaster%2Fapi%2F%3Furl%3Dhttps%3A%2F%2Fwww.instagram.com%2F"+x+"%26xpath%3D%2F%2Fhtml%2Fmeta%5B%40property%3Dog%3Aimage%5D",
    dataType: "json",
    success: function( response ) {
        document.getElementById("inst").innerHTML = '<img id="refImg" src="' + response[0].content + '">';
        updateResults();
        run();
    }
});
  }

</script>
  
  
</head>
<body>
  <h1>profile name: <input type="text" name="ip" id="ip">
    <br>
    <button onclick="Getir(document.getElementById('ip').value)">Getir</button>
     
  </h1>
  <h2 id="inst"></h2>
  <img id="gandhi" src="gandhi.jpg" style="display:none;" >
  <canvas id="cnvimg" class="overlay"/>


  
      

  <script>

    async function uploadRefImage(e) {
      console.log("uploadRefImage()");
      const imgFile = $('#srcImg').get(0).files[0]
      const img = await faceapi.bufferToImage(imgFile)
      $('#refImg').get(0).src = img.src
      updateReferenceImageResults()
    }
    
    async function uploadQueryImage(e) {
      console.log("uploadQueryImage()");
      const imgFile = $('#queryImgUploadInput').get(0).files[0]
      const img = await faceapi.bufferToImage(imgFile)
      $('#queryImg').get(0).src = img.src
      updateQueryImageResults()
    }
    
    async function loadQueryImageFromUrl(url) {
      console.log("loadQueryImageFromUrl()");
      /*
      console.log(url);
      const extimg = await requestExternalImage(url);
      $('#gandhi64').get(0).src = extimg.src
      
      */
      updateReferenceImageResults();
      
    }
    
    /*
    async function updateReferenceImageResults() {
      console.log("updateReferenceImageResults()");
      const inputImgEl = $('#refImg').get(0)
      const canvas = $('#refImgOverlay').get(0)
      const fullFaceDescriptions = await faceapi
        .detectAllFaces(inputImgEl, getFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors()
    }
    */
    
    //yeni yaz覺ld覺
    async function createCanvasImage() {
        console.log("begin canvas");
        var c = document.getElementById("cnvimg");
        var ctx = c.getContext("2d");
        var img = document.getElementById("gandhi"); 
        ctx.drawImage(img, 100, 100);
        console.log("end canvas");
    }
    
    
    // yeni yaz覺ld覺
    async function updateReferenceImageResults() {
      console.log("updateReferenceImageResults()");
      await createCanvasImage();  
      console.log("ok");
      
      const inputImgEl = $('#cnvimg').get(0);
      const options = getFaceDetectorOptions();
      console.log(options);
      console.log(inputImgEl);
      //const canvas = $('#refImgOverlay').get(0)
      //var inp = document.getElementById("gandhi").src;
      
      const detections = await faceapi.detectAllFaces(inputImgEl,options);
      console.log("detections");
      console.log(detections);
      const canvas = $('#cnvimg').get(0)
      //faceapi.matchDimensions(canvas, inputImgEl)
      faceapi.matchDimensions(canvas, inputImgEl)
      //faceapi.draw.drawDetections(canvas, faceapi.resizeResults(results, inputImgEl))
      faceapi.draw.drawDetections(canvas, faceapi.resizeResults(detections, inputImgEl))
    }
    
    async function updateQueryImageResults() {
      console.log("updateQueryImageResults()");
      const inputImgEl = $('#queryImg').get(0)
      const canvas = $('#queryImgOverlay').get(0)
      const results = await faceapi
        .detectAllFaces(inputImgEl, getFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors()
      faceapi.matchDimensions(canvas, inputImgEl)
      // resize detection and landmarks in case displayed image is smaller than
      // original size
      const resizedResults = faceapi.resizeResults(results, inputImgEl)
      resizedResults.forEach(({ detection, descriptor }) => {
        const label = faceMatcher.findBestMatch(descriptor).toString()
        const options = { label }
        const drawBox = new faceapi.draw.DrawBox(detection.box, options)
        drawBox.draw(canvas)
      })
    }
    async function updateResults() {
      console.log("updateResults()");
      //await loadQueryImageFromUrl(document.getElementById("refImg").src);
      await updateReferenceImageResults()
      //await updateQueryImageResults()
    }
    async function run() {
      // load face detection, face landmark model and face recognition models
      await changeFaceDetector('tiny_face_detector')
      //await faceapi.loadFaceLandmarkModel('/')
      await faceapi.loadFaceRecognitionModel('/')
    }
    /*
    $(document).ready(function() {
      renderNavBar('#navbar', 'face_recognition')
      initFaceDetectionControls()
      run()
    })
    */
  </script>
</body>
</html>
